{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v_representacai_propria.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqZOIhJrLldF"
      },
      "source": [
        "O objetivo é construir um classificador de notícias utilizando a base de dados disponibilizada, em que será criada a representação word2vec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "201Z6K3YLCPu"
      },
      "source": [
        "# Criação de representação própria **Word2Vec**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdEKT4NRPQRm"
      },
      "source": [
        "**Spacy** é uma Biblioteca projetada especificamente para uso em produção e ajuda a criar aplicações que processam e abrange grande volumes de textos. [Documentação](https://https://spacy.io/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGmzbTF6N1Pj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeuQX1cmDmWq"
      },
      "source": [
        "Neste estudo vamos:\n",
        "\n",
        " - configurar o modelo\n",
        " - construir o vocabulário a partir do corpus \n",
        " - treinar a representação Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKeYyNy2K-dx"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "KkeQt1q_L_3M",
        "outputId": "02bef2e3-5c9e-488b-cd1f-6ec2bcc38c75"
      },
      "source": [
        "dados_treino = pd.read_csv(\"/content/drive/MyDrive/word2ver/treino.csv\")\n",
        "dados_treino.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>Traficantes controlam quadrilhas de presídios ...</td>\n",
              "      <td>Do interior de presídios federais, os trafican...</td>\n",
              "      <td>2015-06-16</td>\n",
              "      <td>cotidiano</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/cotidiano/2015/06...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67731</th>\n",
              "      <td>Gabriel não deve reforçar o Santos contra o Sã...</td>\n",
              "      <td>O atacante Gabriel voltou a treinar no Santos ...</td>\n",
              "      <td>2015-02-13</td>\n",
              "      <td>esporte</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/esporte/2015/02/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86552</th>\n",
              "      <td>Força-tarefa interdita frigorífico no Paraná p...</td>\n",
              "      <td>Uma força-tarefa de órgãos do trabalho interdi...</td>\n",
              "      <td>2015-05-14</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2015/05/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84043</th>\n",
              "      <td>DAO, o projeto que quer mudar o mundo</td>\n",
              "      <td>Aposto que a maioria dos leitores nunca ouviu ...</td>\n",
              "      <td>2016-05-23</td>\n",
              "      <td>colunas</td>\n",
              "      <td>ronaldolemos</td>\n",
              "      <td>http://www1.folha.uol.com.br/colunas/ronaldole...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24320</th>\n",
              "      <td>Câmara aprova projeto que prevê PPP em termina...</td>\n",
              "      <td>Vereadores de São Paulo aprovaram na noite des...</td>\n",
              "      <td>2015-05-13</td>\n",
              "      <td>cotidiano</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/cotidiano/2015/05...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ...                                               link\n",
              "10004  Traficantes controlam quadrilhas de presídios ...  ...  http://www1.folha.uol.com.br/cotidiano/2015/06...\n",
              "67731  Gabriel não deve reforçar o Santos contra o Sã...  ...  http://www1.folha.uol.com.br/esporte/2015/02/1...\n",
              "86552  Força-tarefa interdita frigorífico no Paraná p...  ...  http://www1.folha.uol.com.br/mercado/2015/05/1...\n",
              "84043              DAO, o projeto que quer mudar o mundo  ...  http://www1.folha.uol.com.br/colunas/ronaldole...\n",
              "24320  Câmara aprova projeto que prevê PPP em termina...  ...  http://www1.folha.uol.com.br/cotidiano/2015/05...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC3otJR_MizB",
        "outputId": "b5b6a87f-7f8f-45df-e8a9-d596f9437055"
      },
      "source": [
        "#!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9pAO6DUOgxF"
      },
      "source": [
        "#criando objeto nlp\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKy3V_99omLg"
      },
      "source": [
        "## Pré-Processamento\n",
        "\n",
        "- Remover stop words, acentuação, números..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQcQsVFBQF7g"
      },
      "source": [
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkDeITiQIvV"
      },
      "source": [
        "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
        "doc = nlp(texto) ## transforma string em token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQp56m4erbuy",
        "outputId": "b60d4e57-51b8-4cc5-9e29-09022f93c7c3"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rio de Janeiro é uma cidade maravilhosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZgBdPd3rddV",
        "outputId": "743094b1-06f5-46a2-ca8f-69c4bb6a6f8a"
      },
      "source": [
        "type(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBZvb4dAr0jJ",
        "outputId": "87e09b6d-7db6-4b44-848d-92241b412a4c"
      },
      "source": [
        "doc[1].is_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lrrGbBCNAmF",
        "outputId": "f4f6acee-afe8-4889-8169-9c3ef67b749e"
      },
      "source": [
        "doc[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Janeiro"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dvw21zEsZa5"
      },
      "source": [
        "### Tratamento do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NxpU3wnsjGU"
      },
      "source": [
        "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"]) # usamos Generator Expressions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1wNG8B7MytB"
      },
      "source": [
        "Remover stop words, caracteres não alfabéticos e retornando apenas títulos com mais de 2 palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uDF_vJffsYJ5",
        "outputId": "3f03c997-140b-48e9-9978-c2edf2217da6"
      },
      "source": [
        "def trata_textos(doc):  # entrada como doc para não tirar as caractisticcaractristics, em vez de textos_para_tratamentos(uma string)\n",
        "  tokens_validos = []\n",
        "  for token in doc:\n",
        "    e_valido = not token.is_stop and token.is_alpha # verifica se o token é valido \n",
        "    if e_valido:\n",
        "      tokens_validos.append(token.text)\n",
        "\n",
        "  if len(tokens_validos) > 2: # somente frases com mais de duas palavras\n",
        "    return \" \".join(tokens_validos)\n",
        "\n",
        "\n",
        "texto = \"Rio de Janeiro 1212122 c****é uma cidade maravilhosa!\" # teste\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAC88Gq-sX_-",
        "outputId": "f76a65bc-739e-4ab3-f53d-ed09a3e8ee20"
      },
      "source": [
        "from time import time\n",
        "\n",
        "t0 = time()\n",
        "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
        "                                                        batch_size = 1000,\n",
        "                                                        n_process = -1)]\n",
        "\n",
        "tf = time() - t0\n",
        "\n",
        "print(tf/60)                             "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.100439675649007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "28npmRXAQaJf",
        "outputId": "0bd7cfdf-7717-42e1-ff4d-babb74a33509"
      },
      "source": [
        "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
        "titulos_tratados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>macron e le pen a o turno frança revés siglas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>governo antecipa balanço e alckmin anuncia que...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>queda maio a atividade econômica sobe junho bc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              titulo\n",
              "0  polêmica marine le pen abomina negacionistas h...\n",
              "1  macron e le pen a o turno frança revés siglas ...\n",
              "2  apesar larga vitória legislativas macron terá ...\n",
              "3  governo antecipa balanço e alckmin anuncia que...\n",
              "4     queda maio a atividade econômica sobe junho bc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCt1fsuWZTVo"
      },
      "source": [
        "# Configuração do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lOikudiDMUa"
      },
      "source": [
        "Os hiperparâmetros são parâmetros que configuram a forma que seu modelo será treinado, por isso são passados antes da fase de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr9FBvXDZRbM"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRBwIAZKZ6u2"
      },
      "source": [
        "**Hiperparâmetros**:\n",
        "- sg = arquitetura de treinamento skipgram: \n",
        "  - 1 = arquiterura skipgram (1 de TRue)\n",
        "  - 0 = cbow (0 para False)\n",
        "- window = quantas palavras serão consideradas antes e depois do contexto\n",
        "- size = possui tamanho fixo do vetor\n",
        "- min_count = considerar palavras com frequencia maior que o min_count\n",
        "- alpha = taxa de custo de interação \n",
        "- min_alpha = taxa de aprendizado minima, deve ser o menor que alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo2PGtnCZ6Et",
        "outputId": "3800ea39-9df6-4813-db05-4932b072448c"
      },
      "source": [
        "w2v_modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7f06a4aeb8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mjWIMLuvYpD"
      },
      "source": [
        "# Construção do vocabulário a partir do corpus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kszPszEXxW6V",
        "outputId": "2062d6ad-a32b-4b3d-9ad9-97417ca41807"
      },
      "source": [
        "## retirando vazios e duplicados\n",
        "print(len(titulos_tratados))\n",
        "\n",
        "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
        "\n",
        "print(len(titulos_tratados))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90000\n",
            "86113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIpx6DVYw0fB"
      },
      "source": [
        "lista_lista_tokens = [titulo.split(\" \")for titulo in titulos_tratados.titulo]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGKnacRtwRx1",
        "outputId": "d071d54d-fb3e-451a-c457-62b404cdf8c2"
      },
      "source": [
        "import logging ##visualizar o processamento \n",
        "\n",
        "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000) ##a cada 5000 titulos ele atualiza o processo "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:03:39,591 : - collecting all words and their counts\n",
            "2021-01-06 13:03:39,592 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-01-06 13:03:39,612 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2021-01-06 13:03:39,627 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2021-01-06 13:03:39,646 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2021-01-06 13:03:39,661 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2021-01-06 13:03:39,684 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2021-01-06 13:03:39,703 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2021-01-06 13:03:39,718 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2021-01-06 13:03:39,741 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2021-01-06 13:03:39,760 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2021-01-06 13:03:39,776 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2021-01-06 13:03:39,791 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2021-01-06 13:03:39,809 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2021-01-06 13:03:39,826 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2021-01-06 13:03:39,840 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2021-01-06 13:03:39,856 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2021-01-06 13:03:39,870 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2021-01-06 13:03:39,888 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2021-01-06 13:03:39,894 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2021-01-06 13:03:39,895 : - Loading a fresh vocabulary\n",
            "2021-01-06 13:03:39,931 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2021-01-06 13:03:39,933 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2021-01-06 13:03:39,979 : - deleting the raw counts dictionary of 39968 items\n",
            "2021-01-06 13:03:39,981 : - sample=0.001 downsamples 11 most-common words\n",
            "2021-01-06 13:03:39,982 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2021-01-06 13:03:40,029 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2021-01-06 13:03:40,030 : - resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANz1e8utDErq"
      },
      "source": [
        "# Treinamento da representação Word2Vec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLV1zuYA0TKE"
      },
      "source": [
        "### Treinamento com arquitetura CBow\n",
        " Colocamos lá em cima a opção *0* no hiperparametro "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2jrEBA4x-1Y",
        "outputId": "df4e480d-b692-4c52-a7ad-15cdbb8a3465"
      },
      "source": [
        "dir(w2v_modelo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_adapt_by_suffix',\n",
              " '_check_input_data_sanity',\n",
              " '_check_training_sanity',\n",
              " '_clear_post_train',\n",
              " '_do_train_epoch',\n",
              " '_do_train_job',\n",
              " '_get_job_params',\n",
              " '_get_thread_working_mem',\n",
              " '_job_producer',\n",
              " '_load_specials',\n",
              " '_log_epoch_end',\n",
              " '_log_epoch_progress',\n",
              " '_log_progress',\n",
              " '_log_train_end',\n",
              " '_minimize_model',\n",
              " '_raw_word_count',\n",
              " '_save_specials',\n",
              " '_set_train_params',\n",
              " '_smart_save',\n",
              " '_train_epoch',\n",
              " '_train_epoch_corpusfile',\n",
              " '_update_job_params',\n",
              " '_worker_loop',\n",
              " '_worker_loop_corpusfile',\n",
              " 'accuracy',\n",
              " 'alpha',\n",
              " 'batch_words',\n",
              " 'build_vocab',\n",
              " 'build_vocab_from_freq',\n",
              " 'callbacks',\n",
              " 'cbow_mean',\n",
              " 'clear_sims',\n",
              " 'compute_loss',\n",
              " 'corpus_count',\n",
              " 'corpus_total_words',\n",
              " 'cum_table',\n",
              " 'delete_temporary_training_data',\n",
              " 'doesnt_match',\n",
              " 'epochs',\n",
              " 'estimate_memory',\n",
              " 'evaluate_word_pairs',\n",
              " 'get_latest_training_loss',\n",
              " 'hashfxn',\n",
              " 'hs',\n",
              " 'init_sims',\n",
              " 'intersect_word2vec_format',\n",
              " 'iter',\n",
              " 'layer1_size',\n",
              " 'load',\n",
              " 'load_word2vec_format',\n",
              " 'log_accuracy',\n",
              " 'max_final_vocab',\n",
              " 'min_alpha',\n",
              " 'min_alpha_yet_reached',\n",
              " 'min_count',\n",
              " 'model_trimmed_post_training',\n",
              " 'most_similar',\n",
              " 'most_similar_cosmul',\n",
              " 'n_similarity',\n",
              " 'negative',\n",
              " 'ns_exponent',\n",
              " 'predict_output_word',\n",
              " 'random',\n",
              " 'reset_from',\n",
              " 'running_training_loss',\n",
              " 'sample',\n",
              " 'save',\n",
              " 'save_word2vec_format',\n",
              " 'score',\n",
              " 'sg',\n",
              " 'similar_by_vector',\n",
              " 'similar_by_word',\n",
              " 'similarity',\n",
              " 'syn0_lockf',\n",
              " 'syn1',\n",
              " 'syn1neg',\n",
              " 'total_train_time',\n",
              " 'train',\n",
              " 'train_count',\n",
              " 'trainables',\n",
              " 'vector_size',\n",
              " 'vocabulary',\n",
              " 'window',\n",
              " 'wmdistance',\n",
              " 'workers',\n",
              " 'wv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTSt-_7L0rDu",
        "outputId": "aaa1056b-20bc-4506-9f68-9570ec75fa78"
      },
      "source": [
        "w2v_modelo.corpus_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_w8-Ixd7E04"
      },
      "source": [
        "Quando treinamento uma rede neural é comum acompanhar seu **loss**, o loss geralmente é atualizado em cada época, mas com gensim Word2Vec não há uma maneira direta de se fazer isso.\n",
        "\n",
        "O método para calcular e armazenar o loss é `model.get_latest_training_loss()`. Porém não se calcula por época, e sim por treinamento completo. Entretanto, podemos driblar este problema configurando uma mensagem de callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpVWo1YS7UEi"
      },
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "# iniciando a chamada callback\n",
        "class callback(CallbackAny2Vec):\n",
        "     def __init__(self):\n",
        "       self.epoch = 0\n",
        "\n",
        "     def on_epoch_end(self, model):\n",
        "       loss = model.get_latest_training_loss()\n",
        "       if self.epoch == 0:\n",
        "           print('Loss após a época {}: {}'.format(self.epoch, loss))\n",
        "       else:\n",
        "           print('Loss após a época {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "       self.epoch += 1\n",
        "       self.loss_previous_step = loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkHu2j5v0dh5",
        "outputId": "12d58c6f-9518-4b37-df55-4bd161b05621"
      },
      "source": [
        "w2v_modelo.train(lista_lista_tokens,\n",
        "                total_examples=w2v_modelo.corpus_count,\n",
        "                epochs = 30,\n",
        "                compute_loss = True,\n",
        "                callbacks=[callback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:51,375 : - Effective 'alpha' higher than previous training cycles\n",
            "2021-01-06 13:43:51,376 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
            "2021-01-06 13:43:52,400 : - EPOCH 1 - PROGRESS: at 70.25% examples, 351331 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:43:52,754 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:52,767 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:52,779 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:52,780 : - EPOCH - 1 : training on 597929 raw words (503117 effective words) took 1.4s, 363205 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 0: 167536.46875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:53,810 : - EPOCH 2 - PROGRESS: at 70.26% examples, 346397 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:43:54,167 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:54,175 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:54,189 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:54,190 : - EPOCH - 2 : training on 597929 raw words (502920 effective words) took 1.4s, 359480 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 1: 169891.5625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:55,207 : - EPOCH 3 - PROGRESS: at 68.61% examples, 344002 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:43:55,565 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:55,587 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:55,600 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:55,601 : - EPOCH - 3 : training on 597929 raw words (502893 effective words) took 1.4s, 360185 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 2: 162861.15625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:56,628 : - EPOCH 4 - PROGRESS: at 70.25% examples, 347712 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:43:56,952 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:56,987 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:56,991 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:56,992 : - EPOCH - 4 : training on 597929 raw words (502935 effective words) took 1.4s, 364615 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 3: 148732.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:58,029 : - EPOCH 5 - PROGRESS: at 70.26% examples, 344442 words/s, in_qsize 3, out_qsize 2\n",
            "2021-01-06 13:43:58,365 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:58,367 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:58,393 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:58,394 : - EPOCH - 5 : training on 597929 raw words (502931 effective words) took 1.4s, 361652 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 4: 148933.3125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:43:59,409 : - EPOCH 6 - PROGRESS: at 70.26% examples, 352307 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:43:59,782 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:43:59,795 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:43:59,801 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:43:59,802 : - EPOCH - 6 : training on 597929 raw words (502843 effective words) took 1.4s, 360478 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 5: 137653.0625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:00,847 : - EPOCH 7 - PROGRESS: at 70.29% examples, 342037 words/s, in_qsize 6, out_qsize 0\n",
            "2021-01-06 13:44:01,182 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:01,218 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:01,219 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:01,222 : - EPOCH - 7 : training on 597929 raw words (502890 effective words) took 1.4s, 357310 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 6: 139424.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:02,253 : - EPOCH 8 - PROGRESS: at 70.26% examples, 346893 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:02,595 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:02,599 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:02,623 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:02,624 : - EPOCH - 8 : training on 597929 raw words (503058 effective words) took 1.4s, 362141 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 7: 119856.625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:03,640 : - EPOCH 9 - PROGRESS: at 68.60% examples, 342566 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:44:03,990 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:04,019 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:04,029 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:04,030 : - EPOCH - 9 : training on 597929 raw words (502956 effective words) took 1.4s, 360181 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 8: 122648.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:05,058 : - EPOCH 10 - PROGRESS: at 71.91% examples, 359768 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:05,380 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:05,389 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:05,404 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:05,407 : - EPOCH - 10 : training on 597929 raw words (502759 effective words) took 1.4s, 371454 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 9: 125676.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:06,439 : - EPOCH 11 - PROGRESS: at 68.60% examples, 337111 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:44:06,792 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:06,808 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:06,813 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:06,814 : - EPOCH - 11 : training on 597929 raw words (502789 effective words) took 1.4s, 359999 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 10: 117605.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:07,842 : - EPOCH 12 - PROGRESS: at 70.26% examples, 347257 words/s, in_qsize 6, out_qsize 1\n",
            "2021-01-06 13:44:08,159 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:08,193 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:08,202 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:08,203 : - EPOCH - 12 : training on 597929 raw words (503018 effective words) took 1.4s, 364861 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 11: 108164.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:09,219 : - EPOCH 13 - PROGRESS: at 70.26% examples, 352531 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:09,594 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:09,598 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:09,620 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:09,622 : - EPOCH - 13 : training on 597929 raw words (502905 effective words) took 1.4s, 358128 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 12: 110423.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:10,641 : - EPOCH 14 - PROGRESS: at 70.26% examples, 350909 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:11,026 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:11,042 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:11,050 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:11,051 : - EPOCH - 14 : training on 597929 raw words (502715 effective words) took 1.4s, 355041 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 13: 113484.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:12,091 : - EPOCH 15 - PROGRESS: at 70.26% examples, 343959 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:12,442 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:12,460 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:12,472 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:12,473 : - EPOCH - 15 : training on 597929 raw words (502978 effective words) took 1.4s, 357107 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 14: 106016.625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:13,508 : - EPOCH 16 - PROGRESS: at 70.26% examples, 345615 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:13,852 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:13,869 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:13,878 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:13,879 : - EPOCH - 16 : training on 597929 raw words (502888 effective words) took 1.4s, 361129 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 15: 98886.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:14,931 : - EPOCH 17 - PROGRESS: at 71.95% examples, 350009 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:15,245 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:15,261 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:15,275 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:15,276 : - EPOCH - 17 : training on 597929 raw words (502670 effective words) took 1.4s, 364805 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 16: 101754.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:16,316 : - EPOCH 18 - PROGRESS: at 73.60% examples, 360169 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:16,602 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:16,629 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:16,633 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:16,634 : - EPOCH - 18 : training on 597929 raw words (503089 effective words) took 1.3s, 373819 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 17: 104839.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:17,655 : - EPOCH 19 - PROGRESS: at 70.26% examples, 349966 words/s, in_qsize 6, out_qsize 1\n",
            "2021-01-06 13:44:17,993 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:18,004 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:18,013 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:18,015 : - EPOCH - 19 : training on 597929 raw words (502923 effective words) took 1.4s, 367385 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 18: 98434.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:19,033 : - EPOCH 20 - PROGRESS: at 71.91% examples, 358805 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:19,341 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:19,362 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:19,371 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:19,372 : - EPOCH - 20 : training on 597929 raw words (502876 effective words) took 1.3s, 373481 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 19: 88142.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:20,396 : - EPOCH 21 - PROGRESS: at 71.93% examples, 356381 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:20,718 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:20,724 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:20,737 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:20,738 : - EPOCH - 21 : training on 597929 raw words (502736 effective words) took 1.4s, 370612 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 20: 99578.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:21,753 : - EPOCH 22 - PROGRESS: at 70.26% examples, 352120 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:44:22,083 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:22,093 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:22,102 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:22,104 : - EPOCH - 22 : training on 597929 raw words (502834 effective words) took 1.4s, 371677 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 21: 85414.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:23,140 : - EPOCH 23 - PROGRESS: at 71.91% examples, 353470 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:23,453 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:23,463 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:23,477 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:23,480 : - EPOCH - 23 : training on 597929 raw words (503099 effective words) took 1.4s, 369105 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 22: 92733.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:24,516 : - EPOCH 24 - PROGRESS: at 71.91% examples, 354984 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:24,831 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:24,852 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:24,855 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:24,856 : - EPOCH - 24 : training on 597929 raw words (502835 effective words) took 1.4s, 370214 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 23: 86502.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:25,885 : - EPOCH 25 - PROGRESS: at 73.58% examples, 363667 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:26,182 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:26,212 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:26,225 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:26,226 : - EPOCH - 25 : training on 597929 raw words (502761 effective words) took 1.4s, 370483 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 24: 77674.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:27,255 : - EPOCH 26 - PROGRESS: at 71.95% examples, 360619 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:27,569 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:27,589 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:27,597 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:27,598 : - EPOCH - 26 : training on 597929 raw words (502809 effective words) took 1.3s, 373761 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 25: 80075.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:28,655 : - EPOCH 27 - PROGRESS: at 71.95% examples, 347086 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:28,963 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:28,985 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:28,988 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:28,990 : - EPOCH - 27 : training on 597929 raw words (502695 effective words) took 1.4s, 365083 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 26: 83533.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:30,018 : - EPOCH 28 - PROGRESS: at 73.60% examples, 364523 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:30,303 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:30,324 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:30,329 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:30,330 : - EPOCH - 28 : training on 597929 raw words (502770 effective words) took 1.3s, 378991 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 27: 85629.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:31,359 : - EPOCH 29 - PROGRESS: at 71.91% examples, 355095 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:31,683 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:31,720 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:31,723 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:31,726 : - EPOCH - 29 : training on 597929 raw words (502726 effective words) took 1.4s, 363271 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 28: 81238.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:32,762 : - EPOCH 30 - PROGRESS: at 73.59% examples, 361007 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:44:33,055 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:44:33,063 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:44:33,084 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:44:33,088 : - EPOCH - 30 : training on 597929 raw words (502863 effective words) took 1.3s, 372574 effective words/s\n",
            "2021-01-06 13:44:33,089 : - training on a 17937870 raw words (15086281 effective words) took 41.7s, 361676 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss após a época 29: 80066.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15086281, 17937870)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xfv_Ukt168p",
        "outputId": "d5064e86-b4c0-4b11-d70a-f5f354eda36c"
      },
      "source": [
        "w2v_modelo.wv.most_similar(\"google\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:44:33,897 : - precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 0.4273000955581665),\n",
              " ('facebook', 0.38305389881134033),\n",
              " ('uber', 0.3599740266799927),\n",
              " ('fbi', 0.35088932514190674),\n",
              " ('amazon', 0.3478612005710602),\n",
              " ('netanyahu', 0.3400176763534546),\n",
              " ('disney', 0.33000797033309937),\n",
              " ('software', 0.3272336423397064),\n",
              " ('news', 0.3262626528739929),\n",
              " ('snapchat', 0.3204635977745056)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COwrgAPn497P",
        "outputId": "d1b973f8-d509-401b-db94-ef6eca4fa55a"
      },
      "source": [
        "w2v_modelo.wv.most_similar(\"microsoft\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('telefónica', 0.41046327352523804),\n",
              " ('amazon', 0.40845006704330444),\n",
              " ('braskem', 0.40362513065338135),\n",
              " ('unilever', 0.3990749716758728),\n",
              " ('canais', 0.395320326089859),\n",
              " ('sky', 0.3939288258552551),\n",
              " ('tesla', 0.3899308145046234),\n",
              " ('lego', 0.3851560354232788),\n",
              " ('viajante', 0.37406665086746216),\n",
              " ('netflix', 0.3730001151561737)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAXTGv5a5QU6",
        "outputId": "5ce56aa0-7d0c-4035-fd91-59214799e3db"
      },
      "source": [
        "w2v_modelo.wv.most_similar(\"barcelona\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bayern', 0.47407281398773193),\n",
              " ('madrid', 0.44254249334335327),\n",
              " ('botafogo', 0.4367230534553528),\n",
              " ('leicester', 0.43565401434898376),\n",
              " ('barça', 0.4255511164665222),\n",
              " ('chelsea', 0.4184545874595642),\n",
              " ('juventus', 0.41743004322052),\n",
              " ('liverpool', 0.41165515780448914),\n",
              " ('lazio', 0.4115499258041382),\n",
              " ('munique', 0.40442782640457153)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Qh4ROK5YN5",
        "outputId": "5cc38bcd-5a90-43e5-a5a0-5af8ccc9591c"
      },
      "source": [
        "w2v_modelo.wv.most_similar(\"messi\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suárez', 0.5018256306648254),\n",
              " ('neymar', 0.4094392657279968),\n",
              " ('barça', 0.40654322504997253),\n",
              " ('tevez', 0.4012410342693329),\n",
              " ('cristiano', 0.3918797969818115),\n",
              " ('ronaldo', 0.3839137554168701),\n",
              " ('calleri', 0.3779301047325134),\n",
              " ('bauza', 0.3762350082397461),\n",
              " ('chuteiras', 0.37445375323295593),\n",
              " ('maradona', 0.36999812722206116)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iog5YXJj8jWC"
      },
      "source": [
        "### Treinamento com arquitetura Skip-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iO06BW8xGU",
        "outputId": "1fe7fdbc-6b70-46be-966d-d343a5129b14"
      },
      "source": [
        "w2v_modelo_sg = Word2Vec(sg = 1,\n",
        "                      window = 5,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
        "\n",
        "w2v_modelo_sg.train(lista_lista_tokens,\n",
        "                total_examples=w2v_modelo_sg.corpus_count,\n",
        "                epochs = 30)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:48:38,673 : - collecting all words and their counts\n",
            "2021-01-06 13:48:38,674 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-01-06 13:48:38,695 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2021-01-06 13:48:38,709 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2021-01-06 13:48:38,725 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2021-01-06 13:48:38,738 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2021-01-06 13:48:38,752 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2021-01-06 13:48:38,771 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2021-01-06 13:48:38,787 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2021-01-06 13:48:38,801 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2021-01-06 13:48:38,818 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2021-01-06 13:48:38,833 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2021-01-06 13:48:38,848 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2021-01-06 13:48:38,861 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2021-01-06 13:48:38,878 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2021-01-06 13:48:38,892 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2021-01-06 13:48:38,907 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2021-01-06 13:48:38,919 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2021-01-06 13:48:38,936 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2021-01-06 13:48:38,940 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2021-01-06 13:48:38,941 : - Loading a fresh vocabulary\n",
            "2021-01-06 13:48:38,983 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2021-01-06 13:48:38,988 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2021-01-06 13:48:39,035 : - deleting the raw counts dictionary of 39968 items\n",
            "2021-01-06 13:48:39,038 : - sample=0.001 downsamples 11 most-common words\n",
            "2021-01-06 13:48:39,039 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2021-01-06 13:48:39,094 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2021-01-06 13:48:39,096 : - resetting layer weights\n",
            "2021-01-06 13:48:41,770 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
            "2021-01-06 13:48:42,823 : - EPOCH 1 - PROGRESS: at 28.48% examples, 136986 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:43,885 : - EPOCH 1 - PROGRESS: at 58.61% examples, 139863 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:44,909 : - EPOCH 1 - PROGRESS: at 88.61% examples, 142421 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:45,212 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:48:45,218 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:48:45,249 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:48:45,250 : - EPOCH - 1 : training on 597929 raw words (503151 effective words) took 3.5s, 144977 effective words/s\n",
            "2021-01-06 13:48:46,281 : - EPOCH 2 - PROGRESS: at 28.48% examples, 140370 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:47,341 : - EPOCH 2 - PROGRESS: at 58.61% examples, 141559 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:48,379 : - EPOCH 2 - PROGRESS: at 88.61% examples, 142931 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:48,644 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:48:48,692 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:48:48,714 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:48:48,715 : - EPOCH - 2 : training on 597929 raw words (502904 effective words) took 3.5s, 145621 effective words/s\n",
            "2021-01-06 13:48:49,805 : - EPOCH 3 - PROGRESS: at 26.80% examples, 125211 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:48:50,878 : - EPOCH 3 - PROGRESS: at 58.60% examples, 136926 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:51,969 : - EPOCH 3 - PROGRESS: at 90.28% examples, 140113 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:52,147 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:48:52,189 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:48:52,225 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:48:52,226 : - EPOCH - 3 : training on 597929 raw words (502878 effective words) took 3.5s, 143806 effective words/s\n",
            "2021-01-06 13:48:53,264 : - EPOCH 4 - PROGRESS: at 28.48% examples, 139274 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:54,317 : - EPOCH 4 - PROGRESS: at 58.60% examples, 141513 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:55,348 : - EPOCH 4 - PROGRESS: at 88.61% examples, 143197 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:55,620 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:48:55,636 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:48:55,655 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:48:55,656 : - EPOCH - 4 : training on 597929 raw words (502799 effective words) took 3.4s, 147079 effective words/s\n",
            "2021-01-06 13:48:56,689 : - EPOCH 5 - PROGRESS: at 28.48% examples, 139717 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:57,771 : - EPOCH 5 - PROGRESS: at 58.61% examples, 139765 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:58,795 : - EPOCH 5 - PROGRESS: at 88.61% examples, 142374 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:48:59,072 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:48:59,082 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:48:59,143 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:48:59,145 : - EPOCH - 5 : training on 597929 raw words (502978 effective words) took 3.5s, 144560 effective words/s\n",
            "2021-01-06 13:49:00,169 : - EPOCH 6 - PROGRESS: at 26.80% examples, 132929 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:01,238 : - EPOCH 6 - PROGRESS: at 56.93% examples, 137279 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:02,306 : - EPOCH 6 - PROGRESS: at 86.97% examples, 138755 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:02,606 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:02,657 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:02,661 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:02,663 : - EPOCH - 6 : training on 597929 raw words (502814 effective words) took 3.5s, 143388 effective words/s\n",
            "2021-01-06 13:49:03,726 : - EPOCH 7 - PROGRESS: at 26.80% examples, 128274 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:04,763 : - EPOCH 7 - PROGRESS: at 56.93% examples, 137001 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:05,808 : - EPOCH 7 - PROGRESS: at 88.61% examples, 142271 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:06,102 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:06,143 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:06,159 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:06,160 : - EPOCH - 7 : training on 597929 raw words (503062 effective words) took 3.5s, 144348 effective words/s\n",
            "2021-01-06 13:49:07,231 : - EPOCH 8 - PROGRESS: at 28.48% examples, 135057 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:08,265 : - EPOCH 8 - PROGRESS: at 58.61% examples, 140597 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:09,299 : - EPOCH 8 - PROGRESS: at 88.62% examples, 142434 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:09,561 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:09,594 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:09,612 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:09,614 : - EPOCH - 8 : training on 597929 raw words (502788 effective words) took 3.4s, 146088 effective words/s\n",
            "2021-01-06 13:49:10,656 : - EPOCH 9 - PROGRESS: at 28.48% examples, 140687 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:11,726 : - EPOCH 9 - PROGRESS: at 58.61% examples, 141076 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:12,776 : - EPOCH 9 - PROGRESS: at 88.61% examples, 142066 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:13,097 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:13,107 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:13,114 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:13,115 : - EPOCH - 9 : training on 597929 raw words (502943 effective words) took 3.5s, 144708 effective words/s\n",
            "2021-01-06 13:49:14,133 : - EPOCH 10 - PROGRESS: at 28.48% examples, 142448 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:15,173 : - EPOCH 10 - PROGRESS: at 56.95% examples, 139895 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:16,222 : - EPOCH 10 - PROGRESS: at 86.96% examples, 141399 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:16,519 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:16,588 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:16,597 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:16,598 : - EPOCH - 10 : training on 597929 raw words (502904 effective words) took 3.5s, 145001 effective words/s\n",
            "2021-01-06 13:49:17,640 : - EPOCH 11 - PROGRESS: at 26.80% examples, 130542 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:18,772 : - EPOCH 11 - PROGRESS: at 58.57% examples, 136016 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:19,793 : - EPOCH 11 - PROGRESS: at 88.62% examples, 139903 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:20,084 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:20,137 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:20,142 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:20,144 : - EPOCH - 11 : training on 597929 raw words (502871 effective words) took 3.5s, 142269 effective words/s\n",
            "2021-01-06 13:49:21,185 : - EPOCH 12 - PROGRESS: at 28.48% examples, 139086 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:22,189 : - EPOCH 12 - PROGRESS: at 55.26% examples, 136583 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:23,198 : - EPOCH 12 - PROGRESS: at 85.30% examples, 141013 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:23,598 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:23,612 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:23,656 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:23,658 : - EPOCH - 12 : training on 597929 raw words (502765 effective words) took 3.5s, 143635 effective words/s\n",
            "2021-01-06 13:49:24,679 : - EPOCH 13 - PROGRESS: at 26.80% examples, 133159 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:25,765 : - EPOCH 13 - PROGRESS: at 58.60% examples, 140374 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:26,792 : - EPOCH 13 - PROGRESS: at 88.62% examples, 142642 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:27,062 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:27,089 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:27,106 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:27,107 : - EPOCH - 13 : training on 597929 raw words (502827 effective words) took 3.4s, 146225 effective words/s\n",
            "2021-01-06 13:49:28,130 : - EPOCH 14 - PROGRESS: at 28.48% examples, 141528 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:29,152 : - EPOCH 14 - PROGRESS: at 56.95% examples, 140754 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:30,213 : - EPOCH 14 - PROGRESS: at 88.62% examples, 144031 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:30,509 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:30,528 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:30,538 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:30,539 : - EPOCH - 14 : training on 597929 raw words (502867 effective words) took 3.4s, 147049 effective words/s\n",
            "2021-01-06 13:49:31,662 : - EPOCH 15 - PROGRESS: at 28.48% examples, 129209 words/s, in_qsize 5, out_qsize 1\n",
            "2021-01-06 13:49:32,706 : - EPOCH 15 - PROGRESS: at 58.57% examples, 136575 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:33,816 : - EPOCH 15 - PROGRESS: at 86.97% examples, 133926 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:34,080 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:34,161 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:34,163 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:34,165 : - EPOCH - 15 : training on 597929 raw words (502924 effective words) took 3.6s, 139215 effective words/s\n",
            "2021-01-06 13:49:35,281 : - EPOCH 16 - PROGRESS: at 30.15% examples, 137984 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:36,359 : - EPOCH 16 - PROGRESS: at 60.28% examples, 139195 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:37,461 : - EPOCH 16 - PROGRESS: at 91.97% examples, 141134 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:49:37,596 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:37,605 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:37,620 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:37,621 : - EPOCH - 16 : training on 597929 raw words (503127 effective words) took 3.4s, 146354 effective words/s\n",
            "2021-01-06 13:49:38,719 : - EPOCH 17 - PROGRESS: at 30.15% examples, 139331 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:39,774 : - EPOCH 17 - PROGRESS: at 60.28% examples, 141432 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:40,810 : - EPOCH 17 - PROGRESS: at 91.94% examples, 145532 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:40,956 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:41,018 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:41,027 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:41,028 : - EPOCH - 17 : training on 597929 raw words (502887 effective words) took 3.4s, 148125 effective words/s\n",
            "2021-01-06 13:49:42,086 : - EPOCH 18 - PROGRESS: at 28.48% examples, 137175 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:43,184 : - EPOCH 18 - PROGRESS: at 60.28% examples, 141330 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:44,215 : - EPOCH 18 - PROGRESS: at 90.28% examples, 143092 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:44,375 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:44,424 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:44,449 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:44,451 : - EPOCH - 18 : training on 597929 raw words (502828 effective words) took 3.4s, 147552 effective words/s\n",
            "2021-01-06 13:49:45,549 : - EPOCH 19 - PROGRESS: at 30.15% examples, 139248 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:46,576 : - EPOCH 19 - PROGRESS: at 61.92% examples, 147166 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:47,591 : - EPOCH 19 - PROGRESS: at 91.94% examples, 147769 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:47,750 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:47,785 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:47,806 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:47,808 : - EPOCH - 19 : training on 597929 raw words (502927 effective words) took 3.3s, 150308 effective words/s\n",
            "2021-01-06 13:49:48,833 : - EPOCH 20 - PROGRESS: at 28.48% examples, 141398 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:49,911 : - EPOCH 20 - PROGRESS: at 60.28% examples, 144921 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:50,917 : - EPOCH 20 - PROGRESS: at 90.27% examples, 146685 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:51,132 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:51,150 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:51,200 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:51,201 : - EPOCH - 20 : training on 597929 raw words (503149 effective words) took 3.4s, 148863 effective words/s\n",
            "2021-01-06 13:49:52,270 : - EPOCH 21 - PROGRESS: at 28.48% examples, 135241 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:53,339 : - EPOCH 21 - PROGRESS: at 60.25% examples, 142381 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:54,376 : - EPOCH 21 - PROGRESS: at 90.28% examples, 143541 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:54,598 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:54,607 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:54,611 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:54,612 : - EPOCH - 21 : training on 597929 raw words (503080 effective words) took 3.4s, 147977 effective words/s\n",
            "2021-01-06 13:49:55,680 : - EPOCH 22 - PROGRESS: at 28.48% examples, 135906 words/s, in_qsize 4, out_qsize 1\n",
            "2021-01-06 13:49:56,763 : - EPOCH 22 - PROGRESS: at 60.28% examples, 141800 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:57,774 : - EPOCH 22 - PROGRESS: at 91.94% examples, 147005 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:49:57,931 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:49:57,968 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:49:57,978 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:49:57,979 : - EPOCH - 22 : training on 597929 raw words (502988 effective words) took 3.4s, 150102 effective words/s\n",
            "2021-01-06 13:49:58,995 : - EPOCH 23 - PROGRESS: at 28.48% examples, 142077 words/s, in_qsize 6, out_qsize 0\n",
            "2021-01-06 13:50:00,003 : - EPOCH 23 - PROGRESS: at 58.61% examples, 146143 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:01,031 : - EPOCH 23 - PROGRESS: at 86.95% examples, 143732 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:01,312 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:01,360 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:01,363 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:01,365 : - EPOCH - 23 : training on 597929 raw words (503089 effective words) took 3.4s, 148997 effective words/s\n",
            "2021-01-06 13:50:02,389 : - EPOCH 24 - PROGRESS: at 26.80% examples, 132939 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:03,486 : - EPOCH 24 - PROGRESS: at 58.61% examples, 139484 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:04,532 : - EPOCH 24 - PROGRESS: at 90.28% examples, 143809 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:04,708 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:04,744 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:04,783 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:04,786 : - EPOCH - 24 : training on 597929 raw words (502885 effective words) took 3.4s, 147462 effective words/s\n",
            "2021-01-06 13:50:05,876 : - EPOCH 25 - PROGRESS: at 30.15% examples, 140949 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:06,887 : - EPOCH 25 - PROGRESS: at 60.28% examples, 145210 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:07,897 : - EPOCH 25 - PROGRESS: at 90.28% examples, 146711 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:08,128 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:08,136 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:08,186 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:08,188 : - EPOCH - 25 : training on 597929 raw words (503027 effective words) took 3.4s, 148548 effective words/s\n",
            "2021-01-06 13:50:09,206 : - EPOCH 26 - PROGRESS: at 28.48% examples, 142130 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:10,252 : - EPOCH 26 - PROGRESS: at 58.61% examples, 143450 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:11,301 : - EPOCH 26 - PROGRESS: at 90.28% examples, 146365 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:11,470 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:11,524 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:11,539 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:11,540 : - EPOCH - 26 : training on 597929 raw words (502969 effective words) took 3.3s, 150581 effective words/s\n",
            "2021-01-06 13:50:12,617 : - EPOCH 27 - PROGRESS: at 28.48% examples, 136096 words/s, in_qsize 5, out_qsize 1\n",
            "2021-01-06 13:50:13,602 : - EPOCH 27 - PROGRESS: at 58.61% examples, 143448 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:14,652 : - EPOCH 27 - PROGRESS: at 88.61% examples, 143661 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:14,916 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:14,952 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:14,967 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:14,970 : - EPOCH - 27 : training on 597929 raw words (502992 effective words) took 3.4s, 147067 effective words/s\n",
            "2021-01-06 13:50:16,075 : - EPOCH 28 - PROGRESS: at 30.15% examples, 139272 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:17,079 : - EPOCH 28 - PROGRESS: at 61.92% examples, 148741 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:18,140 : - EPOCH 28 - PROGRESS: at 91.97% examples, 146637 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:18,319 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:18,330 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:18,337 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:18,339 : - EPOCH - 28 : training on 597929 raw words (502829 effective words) took 3.4s, 150055 effective words/s\n",
            "2021-01-06 13:50:19,399 : - EPOCH 29 - PROGRESS: at 28.48% examples, 137041 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:20,425 : - EPOCH 29 - PROGRESS: at 60.28% examples, 146332 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:21,483 : - EPOCH 29 - PROGRESS: at 91.97% examples, 147919 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:21,643 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:21,663 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:21,669 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:21,670 : - EPOCH - 29 : training on 597929 raw words (502992 effective words) took 3.3s, 151746 effective words/s\n",
            "2021-01-06 13:50:22,690 : - EPOCH 30 - PROGRESS: at 28.48% examples, 141475 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:23,693 : - EPOCH 30 - PROGRESS: at 58.61% examples, 146155 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:24,775 : - EPOCH 30 - PROGRESS: at 88.61% examples, 143984 words/s, in_qsize 5, out_qsize 0\n",
            "2021-01-06 13:50:24,999 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2021-01-06 13:50:25,038 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2021-01-06 13:50:25,063 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2021-01-06 13:50:25,065 : - EPOCH - 30 : training on 597929 raw words (502966 effective words) took 3.4s, 148596 effective words/s\n",
            "2021-01-06 13:50:25,066 : - training on a 17937870 raw words (15088210 effective words) took 103.3s, 146069 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15088210, 17937870)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNJ1Lddn9na8",
        "outputId": "664d02a9-71a5-4e28-f15b-46a66b8e36e2"
      },
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"google\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reguladores', 0.41893380880355835),\n",
              " ('apple', 0.3909544348716736),\n",
              " ('android', 0.38632649183273315),\n",
              " ('buffett', 0.3862176239490509),\n",
              " ('patentes', 0.372905433177948),\n",
              " ('concorda', 0.36265307664871216),\n",
              " ('yahoo', 0.3612287938594818),\n",
              " ('anunciantes', 0.3608386516571045),\n",
              " ('verizon', 0.35400474071502686),\n",
              " ('warren', 0.35376566648483276)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpmuh73y-BOJ",
        "outputId": "c51a5062-de27-40b5-cafb-3175b753a048"
      },
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"microsoft\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('linkedin', 0.5076127648353577),\n",
              " ('chips', 0.49765723943710327),\n",
              " ('kraft', 0.469170480966568),\n",
              " ('heinz', 0.4532616436481476),\n",
              " ('unilever', 0.4500690698623657),\n",
              " ('software', 0.4486843943595886),\n",
              " ('silício', 0.4459594488143921),\n",
              " ('verizon', 0.4356909394264221),\n",
              " ('ciberataques', 0.432153582572937),\n",
              " ('telefónica', 0.42697417736053467)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbHdP9s0-Cqv",
        "outputId": "5f4a0411-a5d5-4c4d-e69e-ae15d84650ed"
      },
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"barcelona\") #teste\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('celta', 0.5669006705284119),\n",
              " ('espanyol', 0.5228727459907532),\n",
              " ('supercopa', 0.49703750014305115),\n",
              " ('villarreal', 0.49059662222862244),\n",
              " ('athletic', 0.48977184295654297),\n",
              " ('sevilla', 0.48323675990104675),\n",
              " ('madrid', 0.46111834049224854),\n",
              " ('wolfsburg', 0.4586392045021057),\n",
              " ('valencia', 0.4560597836971283),\n",
              " ('monaco', 0.45213747024536133)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqXiQ7RD-IFw",
        "outputId": "131e822c-8d3a-4372-9dab-481f6e80c2fd"
      },
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"messi\") #teste"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suárez', 0.5066846609115601),\n",
              " ('barça', 0.49429234862327576),\n",
              " ('benzema', 0.4662396013736725),\n",
              " ('finalizações', 0.4626116156578064),\n",
              " ('cavani', 0.4623824954032898),\n",
              " ('celta', 0.45204073190689087),\n",
              " ('cristiano', 0.4513094425201416),\n",
              " ('neymar', 0.44874292612075806),\n",
              " ('espanyol', 0.43521976470947266),\n",
              " ('neuer', 0.4306640625)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoTz1zrb-7IY"
      },
      "source": [
        "A avaliação de analogias de palavras nesse contexto será diretamento no classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZAQfkCF_kxV",
        "outputId": "c4e8bd57-cc60-4f5a-d023-28a35fd8e96f"
      },
      "source": [
        "w2v_modelo.wv.save_word2vec_format(\"/content/drive/MyDrive/word2ver/modelo_cbow.txt\", binary=False)\n",
        "w2v_modelo_sg.wv.save_word2vec_format(\"/content/drive/MyDrive/word2ver/modelo_skipgram.txt\", binary=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 14:08:45,201 : - storing 13006x300 projection weights into /content/drive/MyDrive/word2ver/modelo_cbow.txt\n",
            "2021-01-06 14:08:48,110 : - storing 13006x300 projection weights into /content/drive/MyDrive/word2ver/modelo_skipgram.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwutW2DyGxzr"
      },
      "source": [
        "# Classificador"
      ]
    }
  ]
}